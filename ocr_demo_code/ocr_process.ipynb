{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"ocr_process.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"_qBeexp75l0s","colab_type":"text"},"source":["# OCR \n","- Tesseract Model:\n","training Google Tesseract pre-train model with 50 Vietnamese fonts\n","- Pre-processing:\n","using \"imgtxtenh\" library to preprocess an image. The function of 'imgtxtenh' is to clean/enhance noisy scanned text images.\n","- Image segmentation:\n","spliting an image into many rows of text. Inheriting the result of CRAFT model and G-DBSCAN(clustering algorithm)"]},{"cell_type":"markdown","metadata":{"id":"xH8jP9Sq5l0t","colab_type":"text"},"source":["# Pre-processing:\n","- Install imgtxtenh following this link: https://github.com/mauvilsa/imgtxtenh\n","- Run command: ./imgtxtenh -p [input_image]  [output_image]\n","\n","# Image segmentation:\n","\n","Notebook: from beginning to clustering stage\n","\n","# Image to text:\n","Notebook: prediction stage\n"]},{"cell_type":"markdown","metadata":{"id":"6M2wu1Sg5l0u","colab_type":"text"},"source":["# Trình tự\n","- Tiền xử lý trên toàn bộ bức ảnh gốc với imgtxtenh để lọc nhiễu và background\n","- Khởi tạo thông số  cho craft model\n","- Dùng craft pretrain model dự đoán vị trí các từ trong ảnh sau khi lọc nhiễu, xoay ảnh nếu cần thiết\n","- Nhóm các từ theo hàng với G-DBSCAN(lưu ý 2 thông số xác định vùng lân cận của giải thuật)\n","- Bóc tách từng dữ liệu theo hàng, tiền xử lý đồng thời dùng tesseract model chuyển từng dòng ảnh sang chữ viết"]},{"cell_type":"markdown","metadata":{"id":"7RaJH1ufmzGI","colab_type":"text"},"source":["Step-by-step:\n","\n","###Step 1: Load image\n","\n","###Step 2: Rotate image (or not)\n","\n","###Step 3: Get the word bounding boxes\n","\n","    • Input: Ảnh màu RGB, có width, height, channel\n","\n","    • Output: Heat map và tọa độ bounding box của word\n","\n","###Step 4: Lưu kết quả là hình ảnh đã có bounding box vào đường dẫn thư mục\n","\n","###Step 5: Tính tọa độ của tâm các bounding box của word (Polys)\n","\n","    • Input: Các Polys đã xác định được từ Step 4\n","\n","    • Output: Tọa độ Central point của từng Polys\n","\n","###Step 6: Chuyển mỗi tọa độ Central Point thành một Object Point, rồi đẩy vào mảng X\n","\n","###Step 7: Reset lại 4 initial parameters của CRAFT (nếu  chạy nhiều ảnh)\n","\n","###Step 8: DBScan từng Point trong Step 7 \n","\n","  • Input: Các Polys đã xác định được từ Step 4\n","\n","  • Output: Gom Point vào các Cluster (các word chung 1 hàng vào chung 1 cluster)\n","\n","###Step 9: Với mỗi cluster tìm được trong Step 8, tạo 1 bounding box (Mỗi hàng text tạo 1 bounding box)\n","\n","  • Output: list chứa các tọa độ của mỗi bounding box vừa tạo \n","    (top_left, bottom_left, top_right,bottom_right)\n","\n","###Step 10: Lưu kết quả là ảnh đã có bounding box vào đường dẫn thư mục\n","\n","###Step 11: In ra nội dung text (dưới dạng chữ đánh máy) đã nhận diện được từ ảnh\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2Lcpp2X65u3g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1598031763073,"user_tz":-420,"elapsed":127399,"user":{"displayName":"HOÀNG NGUYỄN","photoUrl":"","userId":"12466453470484659760"}},"outputId":"785326cb-8f1f-43bf-b102-4cfe6f1c3973"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yehqbz6X6UKQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598031763081,"user_tz":-420,"elapsed":127395,"user":{"displayName":"HOÀNG NGUYỄN","photoUrl":"","userId":"12466453470484659760"}},"outputId":"4cbe70f8-cec8-4dff-d734-46a7000a2d9a"},"source":["%cd \"/content/drive/My Drive/OCR-PIPELINE/ocr_demo_code\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/OCR-PIPELINE/ocr_demo_code\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pl_63CSNnIDH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":991},"executionInfo":{"status":"ok","timestamp":1598031784832,"user_tz":-420,"elapsed":149139,"user":{"displayName":"HOÀNG NGUYỄN","photoUrl":"","userId":"12466453470484659760"}},"outputId":"cf495e89-ffb3-4a5e-b48a-4bd115b8e58d"},"source":["!pip install pyproj\n","!pip install pytesseract\n","!sudo apt install tesseract-ocr"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyproj\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/c3/071e080230ac4b6c64f1a2e2f9161c9737a2bc7b683d2c90b024825000c0/pyproj-2.6.1.post1-cp36-cp36m-manylinux2010_x86_64.whl (10.9MB)\n","\u001b[K     |████████████████████████████████| 10.9MB 2.7MB/s \n","\u001b[?25hInstalling collected packages: pyproj\n","Successfully installed pyproj-2.6.1.post1\n","Collecting pytesseract\n","  Downloading https://files.pythonhosted.org/packages/ba/19/c4c09496657920a859aca0e95db41da5fa6299d1693d7e7ab8ac96677198/pytesseract-0.3.5.tar.gz\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n","Building wheels for collected packages: pytesseract\n","  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytesseract: filename=pytesseract-0.3.5-py2.py3-none-any.whl size=13402 sha256=98fa3bf111a37de73403d78db8c321487eca978960932e8a78c9529dd84d25a8\n","  Stored in directory: /root/.cache/pip/wheels/4c/57/f5/4e60154cc0cfb584373ec7922766e67d00f34879c21ed73f14\n","Successfully built pytesseract\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.5\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'sudo apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  tesseract-ocr-eng tesseract-ocr-osd\n","The following NEW packages will be installed:\n","  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n","0 upgraded, 3 newly installed, 0 to remove and 35 not upgraded.\n","Need to get 4,795 kB of archives.\n","After this operation, 15.8 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n","Fetched 4,795 kB in 1s (4,600 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package tesseract-ocr-eng.\n","(Reading database ... 144487 files and directories currently installed.)\n","Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr-osd.\n","Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n","Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Selecting previously unselected package tesseract-ocr.\n","Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n","Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n","Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rq4OMGjI5l00","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","import time\n","import argparse\n","import getopt\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","\n","from PIL import Image\n","\n","import cv2\n","from skimage import io\n","import numpy as np\n","import craft_utils\n","import imgproc\n","import file_utils\n","import vn2k_to_wgs84\n","\n","from craft import CRAFT\n","# OrderedDict: dictionary subclass that remembers the order that keys were first inserted\n","from collections import OrderedDict\n","import copy\n","import math\n","\n","#import imutils\n","#import matplotlib.pyplot as plt\n","import pytesseract\n","\n","import webbrowser\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11_8ohuVnYJq","colab_type":"code","colab":{}},"source":["UNCLASSIFIED = -2\n","NOISE = -1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9lbfSwIq5l03","colab_type":"text"},"source":["# CRAFT  "]},{"cell_type":"code","metadata":{"id":"UiG7KCPL5l04","colab_type":"code","colab":{}},"source":["\n","def copyStateDict(state_dict):\n","    if list(state_dict.keys())[0].startswith(\"module\"):\n","        start_idx = 1\n","    else:\n","        start_idx = 0\n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        name = \".\".join(k.split(\".\")[start_idx:])\n","        new_state_dict[name] = v\n","    return new_state_dict\n","\n","def str2bool(v):\n","    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hj0wToOc5l07","colab_type":"code","colab":{}},"source":["def test_net(net, canvas_size, mag_ratio, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n","    t0 = time.time()\n","    # resize\n","    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n","    ratio_h = ratio_w = 1 / target_ratio\n","\n","    # preprocessing\n","    x = imgproc.normalizeMeanVariance(img_resized)\n","    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n","    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n","    # print(\"X: \",x)\n","  \n","    if cuda:\n","        x = x.cuda()\n","\n","    # forward pass\n","    with torch.no_grad():\n","        y, feature = net(x)\n","\n","    # make score and link map\n","    score_text = y[0,:,:,0].cpu().data.numpy()\n","    score_link = y[0,:,:,1].cpu().data.numpy()\n","    # print(\"Score_text: \", score_text)\n","    # print(\"Score_link: \", score_link)\n","\n","    # refine link\n","    if refine_net is not None:\n","        with torch.no_grad():\n","            y_refiner = refine_net(y, feature)\n","        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n","    t0 = time.time() - t0\n","    t1 = time.time()\n","\n","    # Post-processing\n","    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n","\n","    # coordinate adjustment\n","    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n","    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n","    for k in range(len(polys)):\n","        if polys[k] is None: polys[k] = boxes[k]\n","    t1 = time.time() - t1\n","\n","    # render results (optional)\n","    render_img = score_text.copy()\n","    render_img = np.hstack((render_img, score_link))\n","    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n","    # print(\"Render image: \", render_img)\n","    # plt.imshow(ret_score_text)\n","    # print(\"Bounding Box: \", polys)\n","\n","    # if show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n","\n","    return boxes, polys, ret_score_text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWM3RiDG5l0-","colab_type":"text"},"source":["# G-DBSCAN"]},{"cell_type":"code","metadata":{"id":"Rm9noINb5l0_","colab_type":"code","colab":{}},"source":["class Point:\n","    '''\n","    Each point have 2 main values: coordinate(lat, long) and cluster_id\n","    '''\n","    def __init__(self, x, y, id):\n","        self.x = x\n","        self.y = y\n","        self.id = id\n","        self.cluster_id = UNCLASSIFIED\n","\n","    def __repr__(self):\n","        return '(x:{}, y:{}, id:{}, cluster:{})' \\\n","            .format(self.x, self.y, self.id, self.cluster_id)\n","\n","#In G-DBScan we use elip instead of circle to cluster (because we mainly use for horizontal text image --> elip is more useful)\n","def n_pred(p1, p2):\n","#     return (p1.x - p2.x)**2/160000 + (p1.y - p2.y)**2/2500 <= 1\n","#     print(p1.x -p2.x)\n","#     print(p1.y -p2.y)\n","#     return (p1.x - p2.x)**2/50000 + (p1.y - p2.y)**2/1500 <= 1\n","#     return (p1.x - p2.x)**2/20000 + (p1.y - p2.y)**2/1300 <= 1\n","#     return (p1.x - p2.x)**2/2000 + (p1.y - p2.y)**2/130 <= 1\n","      return (p1.x - p2.x)**2/500 + (p1.y - p2.y)**2/70 <= 1\n","#     return (p1.x - p2.x)**2/3500 + (p1.y - p2.y)**2/150 <= 1\n","#     return (p1.x - p2.x)**2/7000 + (p1.y - p2.y)**2/1300 <= 1\n","#     return (p1.x - p2.x)**2/8000 + (p1.y - p2.y)**2/300 <= 1\n","#     return (p1.x - p2.x)**2/17000 + (p1.y - p2.y)**2/300 <= 1\n","#     return (p1.x - p2.x)**2/13000 + (p1.y - p2.y)**2/250 <= 1\n","#    return (p1.x - p2.x)**2/15000 + (p1.y - p2.y)**2/180 <= 1\n","\n","\n","def w_card(points):\n","    return len(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"myMcsOBw5l1C","colab_type":"code","colab":{}},"source":["def GDBSCAN(points, n_pred, min_card, w_card):\n","    points = copy.deepcopy(points)\n","    cluster_id = 0\n","    for point in points:\n","        if point.cluster_id == UNCLASSIFIED:\n","            if _expand_cluster(points, point, cluster_id, n_pred, min_card,\n","                               w_card):\n","                cluster_id = cluster_id + 1\n","    clusters = {}\n","    for point in points:\n","        key = point.cluster_id\n","        if key in clusters:\n","            clusters[key].append(point)\n","        else:\n","            clusters[key] = [point]\n","    return list(clusters.values())\n","\n","\n","def _expand_cluster(points, point, cluster_id, n_pred, min_card, w_card):\n","    if not _in_selection(w_card, point):\n","        points.change_cluster_id(point, UNCLASSIFIED)\n","        return False\n","\n","    seeds = points.neighborhood(point, n_pred)\n","    if not _core_point(w_card, min_card, seeds):\n","        points.change_cluster_id(point, NOISE)\n","        return False\n","\n","    points.change_cluster_ids(seeds, cluster_id)\n","    seeds.remove(point)\n","\n","    while len(seeds) > 0:\n","        current_point = seeds[0]\n","        result = points.neighborhood(current_point, n_pred)\n","        if w_card(result) >= min_card:\n","            for p in result:\n","                if w_card([p]) > 0 and p.cluster_id in [UNCLASSIFIED, NOISE]:\n","                    if p.cluster_id == UNCLASSIFIED:\n","                        seeds.append(p)\n","                    points.change_cluster_id(p, cluster_id)\n","        seeds.remove(current_point)\n","    return True\n","\n","\n","def _in_selection(w_card, point):\n","    return w_card([point]) > 0\n","\n","\n","def _core_point(w_card, min_card, points):\n","    return w_card(points) >= min_card\n","\n","\n","class Points:\n","    'Contain list of Point'\n","    def __init__(self, points):\n","        self.points = points\n","\n","    def __iter__(self):\n","        for point in self.points:\n","            yield point\n","\n","    def __repr__(self):\n","        return str(self.points)\n","\n","    def get(self, index):\n","        return self.points[index]\n","\n","    def neighborhood(self, point, n_pred):\n","        return list(filter(lambda x: n_pred(point, x), self.points))\n","\n","    def change_cluster_ids(self, points, value):\n","        for point in points:\n","            self.change_cluster_id(point, value)\n","\n","    def change_cluster_id(self, point, value):\n","        index = (self.points).index(point)\n","        self.points[index].cluster_id = value\n","\n","    def labels(self):\n","        return set(map(lambda x: x.cluster_id, self.points))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"the5lBt25l1F","colab_type":"text"},"source":["# Word detection"]},{"cell_type":"markdown","metadata":{"id":"Ryyz5z_o5l1I","colab_type":"text"},"source":["Load CRAFT pre-train model\n","\n","Load data and apply CRAFT model to recognize word blocks on an image\n","\n","Link github of Craft Model: https://github.com/clovaai/CRAFT-pytorch\n","(Paper of Craft model we used also in this git link)"]},{"cell_type":"code","metadata":{"id":"SqYCzQlp5l1P","colab_type":"code","colab":{}},"source":["# If you need rotate an image, use imutils library and call rotate method with specified number of angle  degrees about the center of the image\n","#In this case we don't need to rotate --> Just skip this step\n","import imutils\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","image = imutils.rotate(image, 90)\n","plt.imshow(image)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6zcwPN65l1o","colab_type":"text"},"source":["# Prediction stage\n","Use tesseract model to convert these segments of an image to text\n"]},{"cell_type":"code","metadata":{"id":"_kqVH9F9-Bdx","colab_type":"code","colab":{}},"source":["def img_to_text(image, image_path):\n","    # Initialize CRAFT parameters\n","    text_threshold = 0.7\n","    low_text = 0.4\n","    link_threshold = 0.4\n","    cuda = False\n","    canvas_size = 1280\n","    mag_ratio = 1.5\n","    # if text image present curve --> poly=true\n","    poly = False\n","    refine = False\n","    show_time = False\n","    refine_net = None\n","    trained_model_path = './craft_mlt_25k.pth'\n","    #trained_model_path = './vgg16.ckpt'\n","\n","    net = CRAFT()\n","    net.load_state_dict(copyStateDict(torch.load(\n","        trained_model_path, map_location='cpu')))\n","    net.eval()\n","\n","    # Apply predict function to the image then get the word bounding boxes\n","    # Use result of pre-trained Craft model to detect word in image by create bounding box for each word\n","    bboxes, polys, score_text = test_net(\n","        net, canvas_size, mag_ratio, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net)\n","\n","    file_utils.saveResult(\n","        image_path, image[:, :, ::-1], bboxes, dirname='./craft_result/')\n","\n","    # Compute coordinate of central point in each bounding box returned by CRAFT\n","    # Purpose: easier for us to make cluster in G-DBScan step\n","    poly_indexes = {}\n","    central_poly_indexes = []\n","    for i in range(len(polys)):\n","        poly_indexes[i] = polys[i]\n","        x_central = (polys[i][0][0] + polys[i][1][0] +\n","                     polys[i][2][0] + polys[i][3][0])/4\n","        y_central = (polys[i][0][1] + polys[i][1][1] +\n","                     polys[i][2][1] + polys[i][3][1])/4\n","        central_poly_indexes.append({i: [int(x_central), int(y_central)]})\n","\n","    X = []\n","    for idx, x in enumerate(central_poly_indexes):\n","        point = Point(x[idx][0], x[idx][1], idx)\n","        X.append(point)\n","\n","    poly = False\n","    refine = False\n","    show_time = False\n","    refine_net = None\n","\n","    clustered = GDBSCAN(Points(X), n_pred, 1, w_card)\n","\n","    cluster_values = []\n","    for cluster in clustered:\n","        sort_cluster = sorted(cluster, key=lambda elem: (elem.x, elem.y))\n","        max_point_id = sort_cluster[len(sort_cluster) - 1].id\n","        min_point_id = sort_cluster[0].id\n","        max_rectangle = sorted(\n","            poly_indexes[max_point_id], key=lambda elem: (elem[0], elem[1]))\n","        min_rectangle = sorted(\n","            poly_indexes[min_point_id], key=lambda elem: (elem[0], elem[1]))\n","\n","        right_above_max_vertex = max_rectangle[len(max_rectangle) - 1]\n","        right_below_max_vertex = max_rectangle[len(max_rectangle) - 2]\n","        left_above_min_vertex = min_rectangle[0]\n","        left_below_min_vertex = min_rectangle[1]\n","\n","        if (int(min_rectangle[0][1]) > int(min_rectangle[1][1])):\n","            left_above_min_vertex = min_rectangle[1]\n","            left_below_min_vertex = min_rectangle[0]\n","        if (int(max_rectangle[len(max_rectangle) - 1][1]) < int(max_rectangle[len(max_rectangle) - 2][1])):\n","            right_above_max_vertex = max_rectangle[len(max_rectangle) - 2]\n","            right_below_max_vertex = max_rectangle[len(max_rectangle) - 1]\n","\n","        cluster_values.append([left_above_min_vertex, left_below_min_vertex,\n","                               right_above_max_vertex, right_below_max_vertex])\n","\n","    file_utils.saveResult(\n","        image_path, image[:, :, ::-1], cluster_values, dirname='./cluster_result/')\n","\n","    img = np.array(image[:, :, ::-1])\n","\n","    res = []\n","    for i, box in enumerate(cluster_values):\n","        poly = np.array(box).astype(np.int32).reshape((-1))\n","        poly = poly.reshape(-1, 2)\n","\n","        rect = cv2.boundingRect(poly)\n","        x, y, w, h = rect\n","        croped = img[y:y+h, x:x+w].copy()\n","\n","        # Preprocess croped segment\n","        croped = cv2.resize(croped, None, fx=5, fy=5,\n","                            interpolation=cv2.INTER_LINEAR)\n","        croped = cv2.cvtColor(croped, cv2.COLOR_BGR2GRAY)\n","        croped = cv2.GaussianBlur(croped, (3, 3), 0)\n","        croped = cv2.bilateralFilter(croped, 5, 25, 25)\n","        croped = cv2.dilate(croped, None, iterations=1)\n","        croped = cv2.threshold(\n","            croped, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n","        # croped = cv2.threshold(croped, 90, 255, cv2.THRESH_BINARY)[1]\n","        croped = cv2.cvtColor(croped, cv2.COLOR_BGR2RGB)\n","\n","        text = pytesseract.image_to_string(croped, lang='eng')\n","        res.append(text)\n","    return res\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aIxUFQ3Ekqzc","colab_type":"code","colab":{}},"source":["def X_Y_localization(listText):\n","  new_text = []\n","  res1 = []\n","  res2 = []\n","  count = {}\n","  for text in listText:\n","    # obmit space and endl in text\n","    text_without_space_endl = ''\n","    for word in text.split():\n","      text_without_space_endl += word\n","    \n","    if len(text_without_space_endl) < 4 or len(text_without_space_endl) > 11:\n","      continue\n","    # modify some easy to misunderstanding features in the text\n","    norm_text = ''\n","    for i in range(len(text_without_space_endl)):\n","        if text_without_space_endl[i] in ['S','$']:\n","          norm_text += '5'\n","        else:\n","          norm_text += text_without_space_endl[i]\n","    new_text.append(norm_text)\n","    # Check the frequency of first 4 letters in norm_text\n","    first_4 = norm_text[0:4]  \n","    if first_4 in count:\n","      count[first_4] += 1\n","    else:\n","      count[first_4] = 1  \n","  max = 0\n","  str1 = ''\n","  for i in count:\n","    if count[i] > max:\n","      max = count[i]\n","      str1 = i\n","  max = 0\n","  str2 = ''\n","  for i in count:\n","    if i != str1 and count[i] > max:\n","      max = count[i]\n","      str2 = i\n","  if not str1.isdigit() or not str2.isdigit():  # 4 so dau tien cuc ki quan trong, neu k xac dinh chinh xac 1 trong 2 thi xem nhu khong tim dc\n","    return res1, res2   # res1 = res2 = [] \n","  avg_len1 = 0\n","  avg_len2 = 0\n","  for text in new_text:\n","    if text[0:4] == str1:\n","      res1.append(text)\n","      if '.' in text:\n","        avg_len1 += len(text)\n","      else:\n","        avg_len1 += len(text) + 1\n","    elif text[0:4] == str2:\n","      res2.append(text)\n","      if '.' in text:\n","        avg_len2 += len(text)\n","      else:\n","        avg_len2 += len(text) + 1\n","  avg_len1 = avg_len1 / len(res1)\n","  avg_len2 = avg_len2 / len(res2)\n","  if avg_len1 > avg_len2:\n","    return res1, res2\n","  else:\n","    return res2, res1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXAdg597lWp5","colab_type":"code","colab":{}},"source":["def norm_X_Y(listX, listY):\n","  if listX == [] or listY == []:\n","    print('Cannot read X,Y from img')\n","    return [],[]\n","  float_listX = []\n","  float_listY = []\n","  for text in listX:\n","    if len(text) < 7:\n","      continue\n","    norm_text = ''\n","    if text.count('.') > 1 or ('.' in text and text.index('.') != 7):\n","      # neu xhien >1 '.' or dau '.' nam sai vi tri (sau chu so thu 7) thi bo toan bo '.' roi them lai sau\n","      for letter in text:\n","        if letter != '.':\n","          norm_text += letter\n","      text = norm_text\n","      norm_text = ''\n","    for i in range(len(text)):\n","      if text[i] == ',':\n","        norm_text += '.'\n","      elif text[i] != '.' and not text[i].isdigit():\n","        norm_text += '5'  # Vi cac so sau sai lech khong anh huong qua lon den toa do nen chuan hoa cac ki tu k phai so thanh 5\n","      else:\n","        norm_text += text[i]\n","    # Xu ly cac truong hop khong co '.'\n","    if norm_text.count('.') == 0:\n","      text = ''\n","      for i in range(len(norm_text)):\n","        if i == 6:\n","          text += norm_text[i] + '.'\n","        else:\n","          text += norm_text[i]\n","    else:\n","      text = norm_text\n","    float_listX.append(float(text))\n","  \n","  for text in listY:\n","    if len(text) < 6:\n","      continue\n","    norm_text = ''\n","    if text.count('.') > 1 or ('.' in text and text.index('.') != 6): \n","      # neu xhien >1 '.' or dau '.' nam sai vi tri (sau chu so thu 6) thi bo toan bo '.' roi them lai sau\n","      for letter in text:\n","        if letter != '.':\n","          norm_text += letter\n","      text = norm_text\n","      norm_text = ''\n","    for i in range(len(text)):\n","      if text[i] == ',':\n","        norm_text += '.'\n","      elif text[i] != '.' and not text[i].isdigit():\n","        norm_text += '5'  # Vi cac so sau sai lech khong anh huong qua lon den toa do nen chuan hoa cac ki tu k phai so thanh 5\n","      else:\n","        norm_text += text[i]\n","    # Xu ly cac truong hop khong co '.'\n","    if norm_text.count('.') == 0:\n","      text = ''\n","      for i in range(len(norm_text)):\n","        if i == 5:\n","          text += norm_text[i] + '.'\n","        else:\n","          text += norm_text[i]\n","    else:\n","      text = norm_text\n","    float_listY.append(float(text))\n","  return float_listX, float_listY"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91aFJJ8fQkYv","colab_type":"code","colab":{}},"source":["def get_X_Y (X,Y):\n","  res_x = 0\n","  res_y = 0\n","  if X == [] or Y == []:\n","    print('Cannot get X,Y. Try another img')\n","    return res_x, res_y\n","  found_x = 0\n","  found_y = 0\n","  for x in X:\n","    for another_x in X:\n","      if abs(another_x - x) > 0 and abs(another_x - x) < 10:\n","        found_x += 1\n","        res_x = (another_x + x) / 2\n","        break\n","    if found_x > 0:\n","      break\n","\n","  for y in Y:\n","    for another_y in Y:\n","      if abs(another_y - y) > 0 and abs(another_y - y) < 10:\n","        found_y += 1\n","        res_y = (another_y + y) / 2\n","        break\n","    if found_y > 0:\n","      break\n","    \n","  if found_x == 0: # lay trung binh cong\n","    for x in X:\n","      res_x += x\n","    res_x = res_x / len(X)\n","  if found_y == 0: # lay trung binh cong\n","    for y in Y:\n","      res_y += y\n","    res_y = res_y / len(Y)\n","  return res_x, res_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRHWNTcXoRXT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598032878770,"user_tz":-420,"elapsed":1049,"user":{"displayName":"HOÀNG NGUYỄN","photoUrl":"","userId":"12466453470484659760"}}},"source":["def main(argv):\n","    inputfile = ''\n","    outputfile = ''\n","    try:\n","        opts, args = getopt.getopt(argv, \"i:\", [\"ifile=\"])\n","    except getopt.GetoptError:\n","        print('Error!')\n","        sys.exit(2)\n","    for opt, arg in opts:\n","        if opt in (\"-i\", \"--ifile\"):\n","            inputfile = arg\n","    image_path = inputfile\n","    image = imgproc.loadImage(image_path)\n","   \n","    \"\"\"\n","    fig2 = plt.figure(figsize=(10, 10))  # create a 10 x 10 figure\n","    ax3 = fig2.add_subplot(111)\n","    ax3.imshow(image, interpolation='none')\n","    ax3.set_title('larger figure')\n","    plt.show()\n","    \"\"\"\n","\n","    listText = img_to_text(image, image_path)\n","    print(listText)\n","    listX, listY = X_Y_localization(listText)\n","    print(listX, listY)\n","    X, Y = norm_X_Y(listX, listY)\n","    print(X, Y)\n","    mid_X, mid_Y = get_X_Y(X, Y)\n","    print(mid_X, mid_Y)\n","    new_Y, new_X = vn2k_to_wgs84.vn2k_to_wgs84(\n","        (mid_Y, mid_X), 9210)  # 9205 ~ 9218, 5896 ~ 5899\n","    print(new_X, new_Y)\n","\n","    print('https://www.google.com/maps/search/?api=1&query=' + str(new_X) + ',' + str(new_Y))\n","    print('https://www.google.com/maps/@?api=1&map_action=pano&center=' + str(new_X) + ',' + str(new_Y) + '&zoom=15')\n","\n","    \"\"\"\n","    ! Not working on colab\n","    webbrowser.open(url)\n","    \"\"\""],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rokoQCioUwd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"ok","timestamp":1598032935752,"user_tz":-420,"elapsed":31930,"user":{"displayName":"HOÀNG NGUYỄN","photoUrl":"","userId":"12466453470484659760"}},"outputId":"2d59f5a7-875c-48c9-b5d8-88cbc7483e51"},"source":["main([\"-i\", \"./input_data/pre_1.jpg.jpg\"])"],"execution_count":25,"outputs":[{"output_type":"stream","text":["['\\x0c', 'be be ae\\n\\x0c', '\\x0c', '\\x0c', '\\x0c', 'Gay\\n\\x0c', '\\x0c', 'BANG\\n\\x0c', 'LAeT\\n\\x0c', 'KP.\\n\\x0c', '\\x0c', '\\x0c', '\\x0c', '\\x0c', '\\x0c', '\\x0c', '\\x0c', '\\x0c', '\\x0c', '¥(m)\\n\\x0c', '\\x0c', 'b201144.76\\n\\x0c', '$91 309.05\\n\\x0c', '\\x0c', '1249031.57\\n\\x0c', 'S91288.63\\n\\x0c', '\\x0c', '1210125.76\\n\\x0c', '§91279.22\\n\\x0c', '\\x0c', '1290138.72\\n\\x0c', 'S9ITTRAI\\n\\x0c', '\\x0c', '1211176.908\\n\\x0c', '$91340.3%6\\n\\x0c', '\\x0c', 'Q21!\\n\\x0c', '\\x0c', '$91348.45\\n\\x0c', '\\x0c', '1211 1444.76\\n\\x0c', '$91309.05\\n\\x0c', 'tiy\\n\\x0c', 'ciip\\n\\x0c', 'gify\\n\\x0c', '\\x0c', 'chirng\\n\\x0c', '\\x0c', 'Nhdng\\n\\x0c', 'thay\\n\\x0c', '\\x0c', 'Sau\\n\\x0c', 'Xac\\n\\x0c', 'nhan\\n\\x0c', 'cua\\n\\x0c', '\\x0c', 'quan\\n\\x0c', 'ddi\\n\\x0c', 'va\\n\\x0c', '\\x0c', 'phap\\n\\x0c', '\\x0c', 'N6i\\n\\x0c', 'dung\\n\\x0c', 'thay\\n\\x0c', 'CO\\n\\x0c', 'tham\\n\\x0c', 'quyén\\n\\x0c', 'cé\\n\\x0c']\n","['1211176.908', '12111444.76'] ['591309.05', '591340.3%6', '591348.45', '591309.05']\n","[1211176.908, 1211144.476] [591309.05, 591340.356, 591348.45, 591309.05]\n","1211160.692 591344.4029999999\n","10.95097064397418 106.5875255899751\n","https://www.google.com/maps/search/?api=1&query=10.95097064397418,106.5875255899751\n","https://www.google.com/maps/@?api=1&map_action=pano&center=10.95097064397418,106.5875255899751&zoom=15\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xqq2xVHKw5eI","colab_type":"text"},"source":["### This allows the program to be called from the command line\n","Does not work in notebook"]},{"cell_type":"code","metadata":{"id":"4erEJ8xmoSDs","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    # * Allows taking arguments from command line\n","    # ls | xargs --replace=$ python post.py -i $ -o post_$\n","    if len(sys.argv) < 2 or sys.argv[1] in ('-h', '--help'):\n","        print(\n","            'Try \\'python {} -i <inputfile>\\'.'.format(sys.argv[0]))\n","        print(\n","            'For bulk use \\'ls | xargs --replace=$ python {} -i $\\'.'.format(sys.argv[0]))\n","        sys.exit()\n","    else:\n","        main(sys.argv[1:])\n"],"execution_count":null,"outputs":[]}]}