{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"ocr_pipeline.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"_qBeexp75l0s","colab_type":"text"},"source":["# OCR \n","- Tesseract Model:\n","training Google Tesseract pre-train model with 50 Vietnamese fonts\n","- Pre-processing:\n","using \"imgtxtenh\" library to preprocess an image. The function of 'imgtxtenh' is to clean/enhance noisy scanned text images.\n","- Image segmentation:\n","spliting an image into many rows of text. Inheriting the result of CRAFT model and G-DBSCAN(clustering algorithm)"]},{"cell_type":"markdown","metadata":{"id":"xH8jP9Sq5l0t","colab_type":"text"},"source":["# Pre-processing:\n","- Install imgtxtenh following this link: https://github.com/mauvilsa/imgtxtenh\n","- Run command: ./imgtxtenh -p [input_image]  [output_image]\n","\n","# Image segmentation:\n","\n","Notebook: from beginning to clustering stage\n","\n","# Image to text:\n","Notebook: prediction stage\n"]},{"cell_type":"markdown","metadata":{"id":"6M2wu1Sg5l0u","colab_type":"text"},"source":["# Trình tự\n","- Tiền xử lý trên toàn bộ bức ảnh gốc với imgtxtenh để lọc nhiễu và background\n","- Khởi tạo thông số  cho craft model\n","- Dùng craft pretrain model dự đoán vị trí các từ trong ảnh sau khi lọc nhiễu, xoay ảnh nếu cần thiết\n","- Nhóm các từ theo hàng với G-DBSCAN(lưu ý 2 thông số xác định vùng lân cận của giải thuật)\n","- Bóc tách từng dữ liệu theo hàng, tiền xử lý đồng thời dùng tesseract model chuyển từng dòng ảnh sang chữ viết"]},{"cell_type":"markdown","metadata":{"id":"7RaJH1ufmzGI","colab_type":"text"},"source":["Step-by-step:\n","\n","###Step 1: Load image\n","\n","###Step 2: Rotate image (or not)\n","\n","###Step 3: Get the word bounding boxes\n","\n","    • Input: Ảnh màu RGB, có width, height, channel\n","\n","    • Output: Heat map và tọa độ bounding box của word\n","\n","###Step 4: Lưu kết quả là hình ảnh đã có bounding box vào đường dẫn thư mục\n","\n","###Step 5: Tính tọa độ của tâm các bounding box của word (Polys)\n","\n","    • Input: Các Polys đã xác định được từ Step 4\n","\n","    • Output: Tọa độ Central point của từng Polys\n","\n","###Step 6: Chuyển mỗi tọa độ Central Point thành một Object Point, rồi đẩy vào mảng X\n","\n","###Step 7: Reset lại 4 initial parameters của CRAFT (nếu  chạy nhiều ảnh)\n","\n","###Step 8: DBScan từng Point trong Step 7 \n","\n","  • Input: Các Polys đã xác định được từ Step 4\n","\n","  • Output: Gom Point vào các Cluster (các word chung 1 hàng vào chung 1 cluster)\n","\n","###Step 9: Với mỗi cluster tìm được trong Step 8, tạo 1 bounding box (Mỗi hàng text tạo 1 bounding box)\n","\n","  • Output: list chứa các tọa độ của mỗi bounding box vừa tạo \n","    (top_left, bottom_left, top_right,bottom_right)\n","\n","###Step 10: Lưu kết quả là ảnh đã có bounding box vào đường dẫn thư mục\n","\n","###Step 11: In ra nội dung text (dưới dạng chữ đánh máy) đã nhận diện được từ ảnh\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2Lcpp2X65u3g","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yehqbz6X6UKQ","colab_type":"code","colab":{}},"source":["%cd \"/content/drive/My Drive/OCR-PIPELINE/ocr_demo_code\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pl_63CSNnIDH","colab_type":"code","colab":{}},"source":["!pip install pyproj\n","!pip install pytesseract\n","!sudo apt install tesseract-ocr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rq4OMGjI5l00","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","import time\n","import argparse\n","import getopt\n","\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","from torch.autograd import Variable\n","\n","from PIL import Image\n","\n","import cv2\n","from skimage import io\n","import numpy as np\n","import ocr_demo_code.craft_utils\n","import ocr_demo_code.imgproc\n","import ocr_demo_code.file_utils\n","import vn2k_to_wgs84.vn2k_to_wgs84\n","\n","from ocr_demo_code.craft import CRAFT\n","# OrderedDict: dictionary subclass that remembers the order that keys were first inserted\n","from collections import OrderedDict\n","import copy\n","import math\n","\n","#import imutils\n","#import matplotlib.pyplot as plt\n","import pytesseract\n","\n","#import webbrowser\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"11_8ohuVnYJq","colab_type":"code","colab":{}},"source":["UNCLASSIFIED = -2\n","NOISE = -1\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9lbfSwIq5l03","colab_type":"text"},"source":["# CRAFT  "]},{"cell_type":"code","metadata":{"id":"UiG7KCPL5l04","colab_type":"code","colab":{}},"source":["\n","def copyStateDict(state_dict):\n","    if list(state_dict.keys())[0].startswith(\"module\"):\n","        start_idx = 1\n","    else:\n","        start_idx = 0\n","    new_state_dict = OrderedDict()\n","    for k, v in state_dict.items():\n","        name = \".\".join(k.split(\".\")[start_idx:])\n","        new_state_dict[name] = v\n","    return new_state_dict\n","\n","def str2bool(v):\n","    return v.lower() in (\"yes\", \"y\", \"true\", \"t\", \"1\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hj0wToOc5l07","colab_type":"code","colab":{}},"source":["def test_net(net, canvas_size, mag_ratio, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net=None):\n","    t0 = time.time()\n","    # resize\n","    img_resized, target_ratio, size_heatmap = imgproc.resize_aspect_ratio(image, canvas_size, interpolation=cv2.INTER_LINEAR, mag_ratio=mag_ratio)\n","    ratio_h = ratio_w = 1 / target_ratio\n","\n","    # preprocessing\n","    x = imgproc.normalizeMeanVariance(img_resized)\n","    x = torch.from_numpy(x).permute(2, 0, 1)    # [h, w, c] to [c, h, w]\n","    x = Variable(x.unsqueeze(0))                # [c, h, w] to [b, c, h, w]\n","    # print(\"X: \",x)\n","  \n","    if cuda:\n","        x = x.cuda()\n","\n","    # forward pass\n","    with torch.no_grad():\n","        y, feature = net(x)\n","\n","    # make score and link map\n","    score_text = y[0,:,:,0].cpu().data.numpy()\n","    score_link = y[0,:,:,1].cpu().data.numpy()\n","    # print(\"Score_text: \", score_text)\n","    # print(\"Score_link: \", score_link)\n","\n","    # refine link\n","    if refine_net is not None:\n","        with torch.no_grad():\n","            y_refiner = refine_net(y, feature)\n","        score_link = y_refiner[0,:,:,0].cpu().data.numpy()\n","    t0 = time.time() - t0\n","    t1 = time.time()\n","\n","    # Post-processing\n","    boxes, polys = craft_utils.getDetBoxes(score_text, score_link, text_threshold, link_threshold, low_text, poly)\n","\n","    # coordinate adjustment\n","    boxes = craft_utils.adjustResultCoordinates(boxes, ratio_w, ratio_h)\n","    polys = craft_utils.adjustResultCoordinates(polys, ratio_w, ratio_h)\n","    for k in range(len(polys)):\n","        if polys[k] is None: polys[k] = boxes[k]\n","    t1 = time.time() - t1\n","\n","    # render results (optional)\n","    render_img = score_text.copy()\n","    render_img = np.hstack((render_img, score_link))\n","    ret_score_text = imgproc.cvt2HeatmapImg(render_img)\n","    # print(\"Render image: \", render_img)\n","    # plt.imshow(ret_score_text)\n","    # print(\"Bounding Box: \", polys)\n","\n","    # if show_time : print(\"\\ninfer/postproc time : {:.3f}/{:.3f}\".format(t0, t1))\n","\n","    return boxes, polys, ret_score_text"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vWM3RiDG5l0-","colab_type":"text"},"source":["# G-DBSCAN"]},{"cell_type":"code","metadata":{"id":"Rm9noINb5l0_","colab_type":"code","colab":{}},"source":["class Point:\n","    '''\n","    Each point have 2 main values: coordinate(lat, long) and cluster_id\n","    '''\n","    def __init__(self, x, y, id):\n","        self.x = x\n","        self.y = y\n","        self.id = id\n","        self.cluster_id = UNCLASSIFIED\n","\n","    def __repr__(self):\n","        return '(x:{}, y:{}, id:{}, cluster:{})' \\\n","            .format(self.x, self.y, self.id, self.cluster_id)\n","\n","#In G-DBScan we use elip instead of circle to cluster (because we mainly use for horizontal text image --> elip is more useful)\n","def n_pred(p1, p2):\n","#     return (p1.x - p2.x)**2/160000 + (p1.y - p2.y)**2/2500 <= 1\n","#     print(p1.x -p2.x)\n","#     print(p1.y -p2.y)\n","#     return (p1.x - p2.x)**2/50000 + (p1.y - p2.y)**2/1500 <= 1\n","#     return (p1.x - p2.x)**2/20000 + (p1.y - p2.y)**2/1300 <= 1\n","#     return (p1.x - p2.x)**2/2000 + (p1.y - p2.y)**2/130 <= 1\n","      return (p1.x - p2.x)**2/500 + (p1.y - p2.y)**2/70 <= 1\n","#     return (p1.x - p2.x)**2/3500 + (p1.y - p2.y)**2/150 <= 1\n","#     return (p1.x - p2.x)**2/7000 + (p1.y - p2.y)**2/1300 <= 1\n","#     return (p1.x - p2.x)**2/8000 + (p1.y - p2.y)**2/300 <= 1\n","#     return (p1.x - p2.x)**2/17000 + (p1.y - p2.y)**2/300 <= 1\n","#     return (p1.x - p2.x)**2/13000 + (p1.y - p2.y)**2/250 <= 1\n","#    return (p1.x - p2.x)**2/15000 + (p1.y - p2.y)**2/180 <= 1\n","\n","\n","def w_card(points):\n","    return len(points)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"myMcsOBw5l1C","colab_type":"code","colab":{}},"source":["def GDBSCAN(points, n_pred, min_card, w_card):\n","    points = copy.deepcopy(points)\n","    cluster_id = 0\n","    for point in points:\n","        if point.cluster_id == UNCLASSIFIED:\n","            if _expand_cluster(points, point, cluster_id, n_pred, min_card,\n","                               w_card):\n","                cluster_id = cluster_id + 1\n","    clusters = {}\n","    for point in points:\n","        key = point.cluster_id\n","        if key in clusters:\n","            clusters[key].append(point)\n","        else:\n","            clusters[key] = [point]\n","    return list(clusters.values())\n","\n","\n","def _expand_cluster(points, point, cluster_id, n_pred, min_card, w_card):\n","    if not _in_selection(w_card, point):\n","        points.change_cluster_id(point, UNCLASSIFIED)\n","        return False\n","\n","    seeds = points.neighborhood(point, n_pred)\n","    if not _core_point(w_card, min_card, seeds):\n","        points.change_cluster_id(point, NOISE)\n","        return False\n","\n","    points.change_cluster_ids(seeds, cluster_id)\n","    seeds.remove(point)\n","\n","    while len(seeds) > 0:\n","        current_point = seeds[0]\n","        result = points.neighborhood(current_point, n_pred)\n","        if w_card(result) >= min_card:\n","            for p in result:\n","                if w_card([p]) > 0 and p.cluster_id in [UNCLASSIFIED, NOISE]:\n","                    if p.cluster_id == UNCLASSIFIED:\n","                        seeds.append(p)\n","                    points.change_cluster_id(p, cluster_id)\n","        seeds.remove(current_point)\n","    return True\n","\n","\n","def _in_selection(w_card, point):\n","    return w_card([point]) > 0\n","\n","\n","def _core_point(w_card, min_card, points):\n","    return w_card(points) >= min_card\n","\n","\n","class Points:\n","    'Contain list of Point'\n","    def __init__(self, points):\n","        self.points = points\n","\n","    def __iter__(self):\n","        for point in self.points:\n","            yield point\n","\n","    def __repr__(self):\n","        return str(self.points)\n","\n","    def get(self, index):\n","        return self.points[index]\n","\n","    def neighborhood(self, point, n_pred):\n","        return list(filter(lambda x: n_pred(point, x), self.points))\n","\n","    def change_cluster_ids(self, points, value):\n","        for point in points:\n","            self.change_cluster_id(point, value)\n","\n","    def change_cluster_id(self, point, value):\n","        index = (self.points).index(point)\n","        self.points[index].cluster_id = value\n","\n","    def labels(self):\n","        return set(map(lambda x: x.cluster_id, self.points))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"the5lBt25l1F","colab_type":"text"},"source":["# Word detection"]},{"cell_type":"markdown","metadata":{"id":"Ryyz5z_o5l1I","colab_type":"text"},"source":["Load CRAFT pre-train model\n","\n","Load data and apply CRAFT model to recognize word blocks on an image\n","\n","Link github of Craft Model: https://github.com/clovaai/CRAFT-pytorch\n","(Paper of Craft model we used also in this git link)"]},{"cell_type":"code","metadata":{"id":"SqYCzQlp5l1P","colab_type":"code","colab":{}},"source":["# If you need rotate an image, use imutils library and call rotate method with specified number of angle  degrees about the center of the image\n","#In this case we don't need to rotate --> Just skip this step\n","import imutils\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","image = imutils.rotate(image, 90)\n","plt.imshow(image)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6zcwPN65l1o","colab_type":"text"},"source":["# Prediction stage\n","Use tesseract model to convert these segments of an image to text\n"]},{"cell_type":"code","metadata":{"id":"_kqVH9F9-Bdx","colab_type":"code","colab":{}},"source":["def img_to_text(image, image_path):\n","    # Initialize CRAFT parameters\n","    text_threshold = 0.7\n","    low_text = 0.4\n","    link_threshold = 0.4\n","    cuda = False\n","    canvas_size = 1280\n","    mag_ratio = 1.5\n","    # if text image present curve --> poly=true\n","    poly = False\n","    refine = False\n","    show_time = False\n","    refine_net = None\n","    trained_model_path = './craft_mlt_25k.pth'\n","    #trained_model_path = './vgg16.ckpt'\n","\n","    net = CRAFT()\n","    net.load_state_dict(copyStateDict(torch.load(\n","        trained_model_path, map_location='cpu')))\n","    net.eval()\n","\n","    # Apply predict function to the image then get the word bounding boxes\n","    # Use result of pre-trained Craft model to detect word in image by create bounding box for each word\n","    bboxes, polys, score_text = test_net(\n","        net, canvas_size, mag_ratio, image, text_threshold, link_threshold, low_text, cuda, poly, refine_net)\n","\n","    file_utils.saveResult(\n","        image_path, image[:, :, ::-1], bboxes, dirname='./craft_result/')\n","\n","    # Compute coordinate of central point in each bounding box returned by CRAFT\n","    # Purpose: easier for us to make cluster in G-DBScan step\n","    poly_indexes = {}\n","    central_poly_indexes = []\n","    for i in range(len(polys)):\n","        poly_indexes[i] = polys[i]\n","        x_central = (polys[i][0][0] + polys[i][1][0] +\n","                     polys[i][2][0] + polys[i][3][0])/4\n","        y_central = (polys[i][0][1] + polys[i][1][1] +\n","                     polys[i][2][1] + polys[i][3][1])/4\n","        central_poly_indexes.append({i: [int(x_central), int(y_central)]})\n","\n","    X = []\n","    for idx, x in enumerate(central_poly_indexes):\n","        point = Point(x[idx][0], x[idx][1], idx)\n","        X.append(point)\n","\n","    poly = False\n","    refine = False\n","    show_time = False\n","    refine_net = None\n","\n","    clustered = GDBSCAN(Points(X), n_pred, 1, w_card)\n","\n","    cluster_values = []\n","    for cluster in clustered:\n","        sort_cluster = sorted(cluster, key=lambda elem: (elem.x, elem.y))\n","        max_point_id = sort_cluster[len(sort_cluster) - 1].id\n","        min_point_id = sort_cluster[0].id\n","        max_rectangle = sorted(\n","            poly_indexes[max_point_id], key=lambda elem: (elem[0], elem[1]))\n","        min_rectangle = sorted(\n","            poly_indexes[min_point_id], key=lambda elem: (elem[0], elem[1]))\n","\n","        right_above_max_vertex = max_rectangle[len(max_rectangle) - 1]\n","        right_below_max_vertex = max_rectangle[len(max_rectangle) - 2]\n","        left_above_min_vertex = min_rectangle[0]\n","        left_below_min_vertex = min_rectangle[1]\n","\n","        if (int(min_rectangle[0][1]) > int(min_rectangle[1][1])):\n","            left_above_min_vertex = min_rectangle[1]\n","            left_below_min_vertex = min_rectangle[0]\n","        if (int(max_rectangle[len(max_rectangle) - 1][1]) < int(max_rectangle[len(max_rectangle) - 2][1])):\n","            right_above_max_vertex = max_rectangle[len(max_rectangle) - 2]\n","            right_below_max_vertex = max_rectangle[len(max_rectangle) - 1]\n","\n","        cluster_values.append([left_above_min_vertex, left_below_min_vertex,\n","                               right_above_max_vertex, right_below_max_vertex])\n","\n","    file_utils.saveResult(\n","        image_path, image[:, :, ::-1], cluster_values, dirname='./cluster_result/')\n","\n","    img = np.array(image[:, :, ::-1])\n","\n","    res = []\n","    for i, box in enumerate(cluster_values):\n","        poly = np.array(box).astype(np.int32).reshape((-1))\n","        poly = poly.reshape(-1, 2)\n","\n","        rect = cv2.boundingRect(poly)\n","        x, y, w, h = rect\n","        croped = img[y:y+h, x:x+w].copy()\n","\n","        # Preprocess croped segment\n","        croped = cv2.resize(croped, None, fx=5, fy=5,\n","                            interpolation=cv2.INTER_LINEAR)\n","        croped = cv2.cvtColor(croped, cv2.COLOR_BGR2GRAY)\n","        croped = cv2.GaussianBlur(croped, (3, 3), 0)\n","        croped = cv2.bilateralFilter(croped, 5, 25, 25)\n","        croped = cv2.dilate(croped, None, iterations=1)\n","        croped = cv2.threshold(\n","            croped, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n","        # croped = cv2.threshold(croped, 90, 255, cv2.THRESH_BINARY)[1]\n","        croped = cv2.cvtColor(croped, cv2.COLOR_BGR2RGB)\n","\n","        text = pytesseract.image_to_string(croped, lang='eng')\n","        res.append(text)\n","    return res\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aIxUFQ3Ekqzc","colab_type":"code","colab":{}},"source":["def X_Y_localization(listText):\n","  new_text = []\n","  res1 = []\n","  res2 = []\n","  count = {}\n","  for text in listText:\n","    # obmit space and endl in text\n","    text_without_space_endl = ''\n","    for word in text.split():\n","      text_without_space_endl += word\n","    \n","    if len(text_without_space_endl) < 4 or len(text_without_space_endl) > 11:\n","      continue\n","    # modify some easy to misunderstanding features in the text\n","    norm_text = ''\n","    for i in range(len(text_without_space_endl)):\n","        if text_without_space_endl[i] in ['S','$']:\n","          norm_text += '5'\n","        else:\n","          norm_text += text_without_space_endl[i]\n","    new_text.append(norm_text)\n","    # Check the frequency of first 4 letters in norm_text\n","    first_4 = norm_text[0:4]  \n","    if first_4 in count:\n","      count[first_4] += 1\n","    else:\n","      count[first_4] = 1  \n","  max = 0\n","  str1 = ''\n","  for i in count:\n","    if count[i] > max:\n","      max = count[i]\n","      str1 = i\n","  max = 0\n","  str2 = ''\n","  for i in count:\n","    if i != str1 and count[i] > max:\n","      max = count[i]\n","      str2 = i\n","  if not str1.isdigit() or not str2.isdigit():  # 4 so dau tien cuc ki quan trong, neu k xac dinh chinh xac 1 trong 2 thi xem nhu khong tim dc\n","    return res1, res2   # res1 = res2 = [] \n","  avg_len1 = 0\n","  avg_len2 = 0\n","  for text in new_text:\n","    if text[0:4] == str1:\n","      res1.append(text)\n","      if '.' in text:\n","        avg_len1 += len(text)\n","      else:\n","        avg_len1 += len(text) + 1\n","    elif text[0:4] == str2:\n","      res2.append(text)\n","      if '.' in text:\n","        avg_len2 += len(text)\n","      else:\n","        avg_len2 += len(text) + 1\n","  avg_len1 = avg_len1 / len(res1)\n","  avg_len2 = avg_len2 / len(res2)\n","  if avg_len1 > avg_len2:\n","    return res1, res2\n","  else:\n","    return res2, res1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXAdg597lWp5","colab_type":"code","colab":{}},"source":["def norm_X_Y(listX, listY):\n","  if listX == [] or listY == []:\n","    print('Cannot read X,Y from img')\n","    return [],[]\n","  float_listX = []\n","  float_listY = []\n","  for text in listX:\n","    if len(text) < 7:\n","      continue\n","    norm_text = ''\n","    if text.count('.') > 1 or ('.' in text and text.index('.') != 7):\n","      # neu xhien >1 '.' or dau '.' nam sai vi tri (sau chu so thu 7) thi bo toan bo '.' roi them lai sau\n","      for letter in text:\n","        if letter != '.':\n","          norm_text += letter\n","      text = norm_text\n","      norm_text = ''\n","    for i in range(len(text)):\n","      if text[i] == ',':\n","        norm_text += '.'\n","      elif text[i] != '.' and not text[i].isdigit():\n","        norm_text += '5'  # Vi cac so sau sai lech khong anh huong qua lon den toa do nen chuan hoa cac ki tu k phai so thanh 5\n","      else:\n","        norm_text += text[i]\n","    # Xu ly cac truong hop khong co '.'\n","    if norm_text.count('.') == 0:\n","      text = ''\n","      for i in range(len(norm_text)):\n","        if i == 6:\n","          text += norm_text[i] + '.'\n","        else:\n","          text += norm_text[i]\n","    else:\n","      text = norm_text\n","    float_listX.append(float(text))\n","  \n","  for text in listY:\n","    if len(text) < 6:\n","      continue\n","    norm_text = ''\n","    if text.count('.') > 1 or ('.' in text and text.index('.') != 6): \n","      # neu xhien >1 '.' or dau '.' nam sai vi tri (sau chu so thu 6) thi bo toan bo '.' roi them lai sau\n","      for letter in text:\n","        if letter != '.':\n","          norm_text += letter\n","      text = norm_text\n","      norm_text = ''\n","    for i in range(len(text)):\n","      if text[i] == ',':\n","        norm_text += '.'\n","      elif text[i] != '.' and not text[i].isdigit():\n","        norm_text += '5'  # Vi cac so sau sai lech khong anh huong qua lon den toa do nen chuan hoa cac ki tu k phai so thanh 5\n","      else:\n","        norm_text += text[i]\n","    # Xu ly cac truong hop khong co '.'\n","    if norm_text.count('.') == 0:\n","      text = ''\n","      for i in range(len(norm_text)):\n","        if i == 5:\n","          text += norm_text[i] + '.'\n","        else:\n","          text += norm_text[i]\n","    else:\n","      text = norm_text\n","    float_listY.append(float(text))\n","  return float_listX, float_listY"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"91aFJJ8fQkYv","colab_type":"code","colab":{}},"source":["def get_X_Y (X,Y):\n","  res_x = 0\n","  res_y = 0\n","  if X == [] or Y == []:\n","    print('Cannot get X,Y. Try another img')\n","    return res_x, res_y\n","  found_x = 0\n","  found_y = 0\n","  for x in X:\n","    for another_x in X:\n","      if abs(another_x - x) > 0 and abs(another_x - x) < 10:\n","        found_x += 1\n","        res_x = (another_x + x) / 2\n","        break\n","    if found_x > 0:\n","      break\n","\n","  for y in Y:\n","    for another_y in Y:\n","      if abs(another_y - y) > 0 and abs(another_y - y) < 10:\n","        found_y += 1\n","        res_y = (another_y + y) / 2\n","        break\n","    if found_y > 0:\n","      break\n","    \n","  if found_x == 0: # lay trung binh cong\n","    for x in X:\n","      res_x += x\n","    res_x = res_x / len(X)\n","  if found_y == 0: # lay trung binh cong\n","    for y in Y:\n","      res_y += y\n","    res_y = res_y / len(Y)\n","  return res_x, res_y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wRHWNTcXoRXT","colab_type":"code","colab":{}},"source":["def main(argv):\n","    inputfile = ''\n","    outputfile = ''\n","    try:\n","        opts, args = getopt.getopt(argv, \"i:\", [\"ifile=\"])\n","    except getopt.GetoptError:\n","        print('Error!')\n","        sys.exit(2)\n","    for opt, arg in opts:\n","        if opt in (\"-i\", \"--ifile\"):\n","            inputfile = arg\n","    image_path = inputfile\n","    image = imgproc.loadImage(image_path)\n","   \n","    \"\"\"\n","    fig2 = plt.figure(figsize=(10, 10))  # create a 10 x 10 figure\n","    ax3 = fig2.add_subplot(111)\n","    ax3.imshow(image, interpolation='none')\n","    ax3.set_title('larger figure')\n","    plt.show()\n","    \"\"\"\n","\n","    listText = img_to_text(image, image_path)\n","    print(listText)\n","    listX, listY = X_Y_localization(listText)\n","    print(listX, listY)\n","    X, Y = norm_X_Y(listX, listY)\n","    print(X, Y)\n","    mid_X, mid_Y = get_X_Y(X, Y)\n","    print(mid_X, mid_Y)\n","    new_X, new_Y = vn2k_to_wgs84.vn2k_to_wgs84((mid_X, mid_Y), 9210) # 9205 ~ 9218, 5896 ~ 5899\n","    print(new_X, new_Y)\n","\n","    new_X = float(int(new_X * 10000000) / 10000000)\n","    new_Y = float(int(new_Y * 10000000) / 10000000)\n","    url = 'https://www.google.com/maps/@?api=1&map_action=map&center=' + str(new_Y) + ',' + str(new_X) + '&zoom=15'\n","\n","    \"\"\"\n","    ! Not working on colab\n","    webbrowser.open(url)\n","    \"\"\"\n","\n","    print(url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3rokoQCioUwd","colab_type":"code","colab":{}},"source":["main([\"-i\", \"./input_data/pre_Page_1.jpg.jpg\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xqq2xVHKw5eI","colab_type":"text"},"source":["### This allows the program to be called from the command line\n","Does not work in notebook"]},{"cell_type":"code","metadata":{"id":"4erEJ8xmoSDs","colab_type":"code","colab":{}},"source":["if __name__ == \"__main__\":\n","    # * Allows taking arguments from command line\n","    # ls | xargs --replace=$ python post.py -i $ -o post_$\n","    if len(sys.argv) < 2 or sys.argv[1] in ('-h', '--help'):\n","        print(\n","            'Try \\'python {} -i <inputfile>\\'.'.format(sys.argv[0]))\n","        print(\n","            'For bulk use \\'ls | xargs --replace=$ python {} -i $\\'.'.format(sys.argv[0]))\n","        sys.exit()\n","    else:\n","        main(sys.argv[1:])\n"],"execution_count":null,"outputs":[]}]}